{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046fd8f8-ad14-4c7f-b759-fec52f5b5306",
   "metadata": {},
   "source": [
    "This notebook processes a dataset of product descriptions by encoding them into dense vector embeddings using a sentence transformer model. The resulting vectors, along with relevant metadata (e.g., price), are stored in a Pinecone index for efficient semantic search and retrieval.\n",
    "\n",
    "Key Components:\n",
    "* Data preprocessing and description extraction\n",
    "* Batch encoding using a transformer model\n",
    "* Metadata handling (price and content)\n",
    "* Pinecone initialization and index creation\n",
    "* Uploading vectors to the Pinecone index in batches\n",
    "\n",
    "**Note:**  \n",
    "Ensure that your Pinecone API key is correctly set in your environment variables before running this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993a2a24-1a58-42be-8034-6d116fb8d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "# import re\n",
    "# import math\n",
    "# import json\n",
    "from tqdm import tqdm\n",
    "# import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from items import Item\n",
    "# from sklearn.manifold import TSNE\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF_USER = \"ed-donner\"\n",
    "# DATASET_NAME = f\"{HF_USER}/pricer-data\"\n",
    "\n",
    "# # Load the dataset\n",
    "# dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "# # Access train and test splits\n",
    "# train = dataset[\"train\"]\n",
    "# test = dataset[\"test\"]\n",
    "\n",
    "# # Save to folders in your current directory\n",
    "# train.save_to_disk(\"./train\")\n",
    "# test.save_to_disk(\"./test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2359ccc0-dbf2-4b1e-9473-e472b32f548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['PINECONE_API_KEY'] = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645167e6-cf0d-42d2-949f-1089a25a2841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log in to HuggingFace\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688bd995-ec3e-43cd-8179-7fe14b275877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Nasir\\Desktop\\AutoDealFinder\\autoenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Muhammad Nasir\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3.1-8B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# With train.pkl in this folder, you can run this:\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2817eaf5-4302-4a18-9148-d1062e3b3dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b80bd7",
   "metadata": {},
   "source": [
    "## Create a Pinecone Vector Datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f95dafd-ab80-464e-ba8a-dec7a2424780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment\n",
    "pinecone_api = os.environ['PINECONE_API_KEY']\n",
    "\n",
    "# Create a Pinecone client instance\n",
    "pc = Pinecone(api_key=pinecone_api)\n",
    "\n",
    "# Index name\n",
    "index_name = \"products\"\n",
    "\n",
    "# Check if index exists and delete it if it does\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "    print(f\"Deleted existing index: {index_name}\")\n",
    "\n",
    "# Create the index with a serverless spec\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392ed28-203d-4e73-be87-ac1390bdf722",
   "metadata": {},
   "source": [
    "# Introducing the SentenceTransfomer\n",
    "\n",
    "The all-MiniLM is a very useful model from HuggingFace that maps sentences & paragraphs to a 384 dimensional dense vector space and is ideal for tasks like semantic search.\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "It can run pretty quickly locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87db200-d19d-44bf-acbd-15c45c70f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38de1bf8-c9b5-45b4-9f4b-86af93b3f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(item):\n",
    "    text = item.prompt.replace(\"How much does this cost to the nearest dollar?\\n\\n\", \"\")\n",
    "    return text.split(\"\\n\\nPrice is $\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adce27b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much does this cost to the nearest dollar?\\n\\nDelphi FG0166 Fuel Pump Module\\nDelphi brings 80 years of OE Heritage into each Delphi pump, ensuring quality and fitment for each Delphi part. Part is validated, tested and matched to the right vehicle application Delphi brings 80 years of OE Heritage into each Delphi assembly, ensuring quality and fitment for each Delphi part Always be sure to check and clean fuel tank to avoid unnecessary returns Rigorous OE-testing ensures the pump can withstand extreme temperatures Brand Delphi, Fit Type Vehicle Specific Fit, Dimensions LxWxH 19.7 x 7.7 x 5.1 inches, Weight 2.2 Pounds, Auto Part Position Unknown, Operation Mode Mechanical, Manufacturer Delphi, Model FUEL PUMP, Dimensions 19.7\\n\\nPrice is $227.00'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before passing into the description function\n",
    "train[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c1205bd-4692-44ef-8ea4-69f255354537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delphi FG0166 Fuel Pump Module\\nDelphi brings 80 years of OE Heritage into each Delphi pump, ensuring quality and fitment for each Delphi part. Part is validated, tested and matched to the right vehicle application Delphi brings 80 years of OE Heritage into each Delphi assembly, ensuring quality and fitment for each Delphi part Always be sure to check and clean fuel tank to avoid unnecessary returns Rigorous OE-testing ensures the pump can withstand extreme temperatures Brand Delphi, Fit Type Vehicle Specific Fit, Dimensions LxWxH 19.7 x 7.7 x 5.1 inches, Weight 2.2 Pounds, Auto Part Position Unknown, Operation Mode Mechanical, Manufacturer Delphi, Model FUEL PUMP, Dimensions 19.7'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before passing into the description function\n",
    "description(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c79e2fe-1f50-4ebf-9a93-34f3088f2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:44:21<00:00, 125.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# train_to_use=train[0:25_000]\n",
    "# for i in tqdm(range(0, len(train_to_use), 1000)):\n",
    "#     batch = train_to_use[i: i+1000]\n",
    "\n",
    "#     # Get the text description from each item\n",
    "#     documents = [description(item) for item in batch]\n",
    "\n",
    "#     # Get the vector embeddings\n",
    "#     vectors = model.encode(documents).astype(float).tolist()\n",
    "\n",
    "#     # Build the list of items to send to Pinecone\n",
    "#     to_upsert = []\n",
    "#     for j, (vector, item) in enumerate(zip(vectors, batch), start=i):\n",
    "#         doc_id = f\"doc_{j}\"  # unique id for Pinecone\n",
    "#         metadata = {\"price\": item[\"price\"]}  # only price in metadata\n",
    "#         to_upsert.append((doc_id, vector, metadata))\n",
    "\n",
    "#     # Upload to Pinecone\n",
    "#     index.upsert(vectors=to_upsert)\n",
    "\n",
    "# for i in tqdm(range(0, len(train), 1000)):\n",
    "#     documents = [description(item) for item in train[i: i+1000]]\n",
    "#     vectors = model.encode(documents).astype(float).tolist()\n",
    "#     metadatas = [{\"category\": item.category, \"price\": item.price} for item in train[i: i+1000]]\n",
    "#     ids = [f\"doc_{j}\" for j in range(i, i+1000)]\n",
    "#     collection.add(\n",
    "#         ids=ids,\n",
    "#         documents=documents,\n",
    "#         embeddings=vectors,\n",
    "#         metadatas=metadatas\n",
    "#     )\n",
    "\n",
    "train_to_use=train[0:50_000]\n",
    "# Loop through your dataset in batches of 1000\n",
    "for i in tqdm(range(0, len(train_to_use), 1000)):\n",
    "    \n",
    "    batch = train_to_use[i: i+1000]\n",
    "\n",
    "    # Extract the descriptions from each item\n",
    "    documents = [description(item) for item in batch]\n",
    "\n",
    "    # Generate vector embeddings for each description\n",
    "    vectors = model.encode(documents).astype(float).tolist()\n",
    "\n",
    "    # Prepare metadata (only include price, since 'category' may not exist)\n",
    "    metadatas = [{\"category\": item.category, \"price\": item.price} for item in batch]\n",
    "\n",
    "    # Create unique IDs for each document\n",
    "    ids = [f\"doc_{j}\" for j in range(i, i+len(batch))]\n",
    "\n",
    "    # Format for Pinecone: (id, vector, metadata)\n",
    "    to_upsert = list(zip(ids, vectors, metadatas))\n",
    "\n",
    "    # Upload to Pinecone index\n",
    "    index.upsert(vectors=to_upsert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a7a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
